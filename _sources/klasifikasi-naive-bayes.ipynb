{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Klasifikasi Naive Bayes***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Penjelasan Naive Bayes**\n",
    "\n",
    "Klasifikasi Naïve Bayes adalah algoritma pembelajaran mesin terbimbing yang digunakan untuk tugas klasifikasi seperti klasifikasi teks. Algoritma ini menggunakan prinsip probabilitas untuk melakukan tugas klasifikasi.\n",
    "\n",
    "Naïve Bayes juga dikenal sebagai pengklasifikasi probabilistik karena didasarkan pada Teorema Bayes. Akan sulit untuk menjelaskan algoritma ini tanpa menjelaskan dasar-dasar statistik Bayesian. Teorema ini, yang juga dikenal sebagai Aturan Bayes, memungkinkan kita untuk \"membalikkan\" probabilitas bersyarat. Sebagai pengingat, probabilitas bersyarat mewakili probabilitas suatu peristiwa jika beberapa peristiwa lain telah terjadi \n",
    "\n",
    "## **Rumus Naive Bayes**\n",
    "\n",
    "$$\n",
    "    P(x|y) = \\frac{P(y|x) \\cdot P(x)}{P(y)}\n",
    "$$\n",
    "\n",
    "Di mana:\n",
    "-  $P(x|y)$  = Probabilitas kejadian **A** terjadi jika **B** diketahui (probabilitas posterior).\n",
    "-  $P(y|x)$  = Probabilitas **B** terjadi jika **A** diketahui (likelihood).\n",
    "-  $P(x)$  = Probabilitas awal dari kejadian **A** (prior probability).\n",
    "-  $P(y)$  = Probabilitas awal dari kejadian **B**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cara Kerja Naive Bayes**\n",
    "\n",
    "Misalkan kita ingin mengklasifikasikan email sebagai **\"Spam\"** atau **\"Bukan Spam\"**, berdasarkan kata-kata dalam email.\n",
    "\n",
    "1. **Menghitung Prior Probability**  \n",
    "   - Hitung probabilitas dasar masing-masing kelas:  \n",
    "   \n",
    "     $\n",
    "     P(Spam) = \\frac{\\text{Jumlah email spam}}{\\text{Total email}}\n",
    "     $\n",
    "     \n",
    "     $\n",
    "     P(BukanSpam) = \\frac{\\text{Jumlah email bukan spam}}{\\text{Total email}}\n",
    "     $\n",
    "\n",
    "2. **Menghitung Likelihood (P(W|C))**  \n",
    "   - Untuk setiap kata dalam email, hitung probabilitas kata tersebut muncul dalam email spam dan bukan spam.\n",
    "\n",
    "3. **Menghitung Posterior Probability**  \n",
    "   - Gunakan rumus Bayes untuk menghitung probabilitas email tersebut menjadi spam atau bukan, lalu pilih kelas dengan probabilitas terbesar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Jenis jenis Naive Bayes**\n",
    "\n",
    "Tergantung pada jenis tipe data yang digunakan, ada beberapa jenis Naive Bayes yang dapat digunakan juga pada beberapa tipe data tertentu agar hasil yang diperoleh dapa lebih maksimal\n",
    "\n",
    "### **a) Gaussian Naive Bayes**\n",
    "\n",
    "- Digunakan untuk data **kontinu** (misalnya tinggi badan, berat badan).  \n",
    "- Mengasumsikan bahwa fitur mengikuti distribusi Gaussian (Normal).  \n",
    "\n",
    "Jika $ x_i $ adalah fitur dengan nilai kontinu, maka probabilitasnya dihitung dengan distribusi normal:\n",
    "\n",
    "$$\n",
    "P(x_i | C) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i - \\mu)^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "Di mana:\n",
    "- $ \\mu $ adalah rata-rata (mean) fitur dalam kelas tertentu.\n",
    "- $ \\sigma^2 $ adalah varians fitur dalam kelas tersebut.\n",
    "\n",
    "Contoh: Jika kita ingin mengklasifikasikan apakah seseorang tinggi atau pendek berdasarkan tinggi badan, kita bisa menggunakan Gaussian Naïve Bayes.\n",
    "\n",
    "### **b) Multinomial Naive Bayes**\n",
    "\n",
    "- Cocok untuk data **diskrit** seperti **teks** (jumlah kata dalam dokumen).  \n",
    "- Menghitung probabilitas suatu kata muncul dalam dokumen yang termasuk dalam kelas tertentu.\n",
    "\n",
    "Formula probabilitasnya adalah:\n",
    "\n",
    "$$\n",
    "P(x_i | C) = \\frac{count(x_i, C) + 1}{\\sum_{j} count(x_j, C) + V}\n",
    "$$\n",
    "\n",
    "Di mana:\n",
    "- $ count(x_i, C) $ = Jumlah kemunculan kata $ x_i $ dalam kelas $ C $.\n",
    "- $ V $ = Jumlah total kata unik dalam seluruh dokumen.\n",
    "\n",
    "Contoh: Digunakan dalam **klasifikasi email spam**, di mana kata-kata tertentu lebih sering muncul dalam email spam dibandingkan email biasa.\n",
    "\n",
    "\n",
    "### **c) Bernoulli Naive Bayes**\n",
    "\n",
    "- Digunakan untuk **data biner** (ya/tidak, ada/tidak).  \n",
    "- Menghitung probabilitas suatu fitur muncul dalam suatu kelas berdasarkan kejadian biner.\n",
    "\n",
    "Formula probabilitasnya:\n",
    "\n",
    "$$\n",
    "P(x_i | C) = p^{x_i} (1 - p)^{1 - x_i}\n",
    "$$\n",
    "\n",
    "Di mana:\n",
    "- $ p $ adalah probabilitas kata $ x_i $ muncul dalam kelas $ C $.\n",
    "- $ x_i $ bernilai **1** jika kata ada, dan **0** jika kata tidak ada.\n",
    "\n",
    "Contoh: Digunakan dalam **filter email spam** berdasarkan ada/tidaknya kata-kata tertentu dalam email.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Perbandingan Perhitungan Data Naive Bayes***\n",
    "\n",
    "Perbandingan ini dilakukan dengan data iris yang sudah kita kumpulkan pada pertemuan sebelumnya agar lebih mudah mendapatkan data datanya. Pada code paling awal kita akan menghubungkannya terlebih dahulu dengan Database. Selanjutnya adalah perhitungan Naive Bayes yang menggunakan data outliers atau data Kotor. Setelah itu kita bersihkan data dari outliers dengan menggunakan rumus LOF pada materi sebelumnya, dan menghitung data bersih tersebut menggunakan Naive Bayes. untuk yang terakhir adalah memberikan hasil dari masing masing perhitungan. Lalu pengungkapan kesimpulan dari hasil yang sudah didapatkan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengimport Library yang digunakan dalam prosesnya\n",
    "import pymysql\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import base64\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL 16.8 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 14.2.1 20240912 (Red Hat 14.2.1-3), 64-bit\n",
      "\n",
      "Berikut ini adalah tampilan data yang diambil dari database :\n",
      "\n",
      "      id           class  petal_length  petal_width  sepal length  sepal width\n",
      "0      1     Iris-setosa          86.4         70.0          20.1         30.5\n",
      "1      2     Iris-setosa           1.4          0.2           4.9          3.0\n",
      "2      3     Iris-setosa           1.3          0.2           4.7          3.2\n",
      "3      4     Iris-setosa           1.5          0.2           4.6          3.1\n",
      "4      5     Iris-setosa           1.4          0.2           5.0          3.6\n",
      "..   ...             ...           ...          ...           ...          ...\n",
      "145  146  Iris-virginica           5.2          2.3           6.7          3.0\n",
      "146  147  Iris-virginica           5.0          1.9           6.3          2.5\n",
      "147  148  Iris-virginica           5.2          2.0           6.5          3.0\n",
      "148  149  Iris-virginica           5.4          2.3           6.2          3.4\n",
      "149  150  Iris-virginica           5.1          1.8           5.9          3.0\n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mengkoneksi database dengan python\n",
    "\n",
    "# for mysql\n",
    "timeout = 10\n",
    "connection = pymysql.connect(\n",
    "    charset=\"utf8mb4\",\n",
    "    connect_timeout=timeout,\n",
    "    cursorclass=pymysql.cursors.DictCursor,\n",
    "    db=\"defaultdb\",\n",
    "    host=\"mysql-726cd75-mysqlpendata-11.h.aivencloud.com\",\n",
    "    password=\"AVNS_LHA80D-LNsKI6wncjfc\",\n",
    "    read_timeout=timeout,\n",
    "    port=20734,\n",
    "    user=\"avnadmin\",\n",
    "    write_timeout=timeout,\n",
    ")\n",
    "mysql_engine = create_engine(\"mysql+pymysql://avnadmin:AVNS_LHA80D-LNsKI6wncjfc@mysql-726cd75-mysqlpendata-11.h.aivencloud.com:20734/defaultdb\")\n",
    "\n",
    "\n",
    "\n",
    "# for postgre\n",
    "def main():\n",
    "    conn = psycopg2.connect('postgres://avnadmin:AVNS__Y6I8K0T7rSnwnRgE1U@pg-3266d3cf-postgresqlpendata-11.h.aivencloud.com:20817/defaultdb?sslmode=require')\n",
    "\n",
    "    query_sql = 'SELECT VERSION()'\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query_sql)\n",
    "\n",
    "    version = cur.fetchone()[0]\n",
    "    print(version)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "postgres_engine = create_engine(\"postgresql+psycopg2://avnadmin:AVNS__Y6I8K0T7rSnwnRgE1U@pg-3266d3cf-postgresqlpendata-11.h.aivencloud.com:20817/defaultdb\")\n",
    "\n",
    "# Ambil data dari MySQL\n",
    "mysql_query = \"SELECT * FROM iris_data\"\n",
    "mysql_df = pd.read_sql(mysql_query, mysql_engine)\n",
    "\n",
    "# Ambil data dari PostgreSQL\n",
    "pg_query = 'SELECT * FROM postgre'\n",
    "pg_df = pd.read_sql(pg_query, postgres_engine)\n",
    "\n",
    "merge_df = pd.merge(mysql_df, pg_df, left_on=\"id\", right_on='id', how='outer')\n",
    "\n",
    "# Menampilkan data yang diambil database dan ditampilkan dalam bentuk tabel\n",
    "selected_columns = [\"id\", \"class\", \"petal_length\", \"petal_width\", \"sepal length\", \"sepal width\"]  \n",
    "filtered_df = merge_df[selected_columns]\n",
    "\n",
    "print()\n",
    "print(\"Berikut ini adalah tampilan data yang diambil dari database :\")\n",
    "print()\n",
    "print(filtered_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Membandingkan Data dengan Outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Model Naïve Bayes: 1.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    'id': range(1, 151),\n",
    "    'class': ['Iris-setosa'] * 50 + ['Iris-versicolor'] * 50 + ['Iris-virginica'] * 50,\n",
    "    'petal_length': filtered_df['petal_length'],\n",
    "    'petal_width': filtered_df['petal_width'],\n",
    "    'sepal length': filtered_df['sepal length'],\n",
    "    'sepal width': filtered_df['sepal width']\n",
    "})\n",
    "\n",
    "# === 2. Data Preprocessing ===\n",
    "data = data.drop(columns=['id'])  # Hapus kolom ID karena tidak diperlukan\n",
    "X = data.drop(columns=['class'])  # Fitur (features)\n",
    "y = data['class']  # Label (target)\n",
    "\n",
    "# === 3. Membagi Data menjadi Training dan Testing (80%-20%) ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === 4. Melatih Model Naïve Bayes ===\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# === 5. Prediksi & Evaluasi ===\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Akurasi Model Naïve Bayes:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Membandingkan Data tanpa Outliers*\n",
    "\n",
    "1. Proses filtering :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indeks-0 → LOF: 135.5942, Label: Outlier\n",
      "Indeks-1 → LOF: 1.0776, Label: Inlier\n",
      "Indeks-2 → LOF: 1.0697, Label: Inlier\n",
      "Indeks-3 → LOF: 1.0050, Label: Inlier\n",
      "Indeks-4 → LOF: 1.0453, Label: Inlier\n",
      "Indeks-5 → LOF: 1.2883, Label: Inlier\n",
      "Indeks-6 → LOF: 1.0516, Label: Inlier\n",
      "Indeks-7 → LOF: 0.9114, Label: Inlier\n",
      "Indeks-8 → LOF: 1.0996, Label: Inlier\n",
      "Indeks-9 → LOF: 0.9596, Label: Inlier\n",
      "Indeks-10 → LOF: 1.2623, Label: Inlier\n",
      "Indeks-11 → LOF: 1.0550, Label: Inlier\n",
      "Indeks-12 → LOF: 0.9596, Label: Inlier\n",
      "Indeks-13 → LOF: 1.0592, Label: Inlier\n",
      "Indeks-14 → LOF: 1.1404, Label: Inlier\n",
      "Indeks-15 → LOF: 1.1932, Label: Inlier\n",
      "Indeks-16 → LOF: 1.1637, Label: Inlier\n",
      "Indeks-17 → LOF: 1.0582, Label: Inlier\n",
      "Indeks-18 → LOF: 1.3447, Label: Inlier\n",
      "Indeks-19 → LOF: 0.9854, Label: Inlier\n",
      "Indeks-20 → LOF: 1.6460, Label: Outlier\n",
      "Indeks-21 → LOF: 1.0483, Label: Inlier\n",
      "Indeks-22 → LOF: 2.0784, Label: Outlier\n",
      "Indeks-23 → LOF: 1.2242, Label: Inlier\n",
      "Indeks-24 → LOF: 1.4252, Label: Inlier\n",
      "Indeks-25 → LOF: 1.1547, Label: Inlier\n",
      "Indeks-26 → LOF: 1.2059, Label: Inlier\n",
      "Indeks-27 → LOF: 0.8843, Label: Inlier\n",
      "Indeks-28 → LOF: 0.8843, Label: Inlier\n",
      "Indeks-29 → LOF: 1.0455, Label: Inlier\n",
      "Indeks-30 → LOF: 1.0109, Label: Inlier\n",
      "Indeks-31 → LOF: 1.6460, Label: Outlier\n",
      "Indeks-32 → LOF: 1.2731, Label: Inlier\n",
      "Indeks-33 → LOF: 1.1304, Label: Inlier\n",
      "Indeks-34 → LOF: 0.9596, Label: Inlier\n",
      "Indeks-35 → LOF: 1.2613, Label: Inlier\n",
      "Indeks-36 → LOF: 1.3443, Label: Inlier\n",
      "Indeks-37 → LOF: 0.9596, Label: Inlier\n",
      "Indeks-38 → LOF: 1.1437, Label: Inlier\n",
      "Indeks-39 → LOF: 1.0691, Label: Inlier\n",
      "Indeks-40 → LOF: 1.0453, Label: Inlier\n",
      "Indeks-41 → LOF: 2.6810, Label: Outlier\n",
      "Indeks-42 → LOF: 0.9731, Label: Inlier\n",
      "Indeks-43 → LOF: 1.0813, Label: Inlier\n",
      "Indeks-44 → LOF: 1.3657, Label: Inlier\n",
      "Indeks-45 → LOF: 1.1065, Label: Inlier\n",
      "Indeks-46 → LOF: 0.9854, Label: Inlier\n",
      "Indeks-47 → LOF: 1.0919, Label: Inlier\n",
      "Indeks-48 → LOF: 1.1719, Label: Inlier\n",
      "Indeks-49 → LOF: 1.1009, Label: Inlier\n",
      "Indeks-50 → LOF: 1.0938, Label: Inlier\n",
      "Indeks-51 → LOF: 1.0635, Label: Inlier\n",
      "Indeks-52 → LOF: 1.1193, Label: Inlier\n",
      "Indeks-53 → LOF: 0.9988, Label: Inlier\n",
      "Indeks-54 → LOF: 1.0218, Label: Inlier\n",
      "Indeks-55 → LOF: 1.2349, Label: Inlier\n",
      "Indeks-56 → LOF: 1.1153, Label: Inlier\n",
      "Indeks-57 → LOF: 1.0902, Label: Inlier\n",
      "Indeks-58 → LOF: 0.9917, Label: Inlier\n",
      "Indeks-59 → LOF: 1.5936, Label: Outlier\n",
      "Indeks-60 → LOF: 1.0625, Label: Inlier\n",
      "Indeks-61 → LOF: 1.3585, Label: Inlier\n",
      "Indeks-62 → LOF: 1.7294, Label: Outlier\n",
      "Indeks-63 → LOF: 1.0918, Label: Inlier\n",
      "Indeks-64 → LOF: 1.6340, Label: Outlier\n",
      "Indeks-65 → LOF: 0.9294, Label: Inlier\n",
      "Indeks-66 → LOF: 1.2277, Label: Inlier\n",
      "Indeks-67 → LOF: 1.1168, Label: Inlier\n",
      "Indeks-68 → LOF: 1.1632, Label: Inlier\n",
      "Indeks-69 → LOF: 1.0137, Label: Inlier\n",
      "Indeks-70 → LOF: 1.0278, Label: Inlier\n",
      "Indeks-71 → LOF: 1.1467, Label: Inlier\n",
      "Indeks-72 → LOF: 1.0451, Label: Inlier\n",
      "Indeks-73 → LOF: 0.9705, Label: Inlier\n",
      "Indeks-74 → LOF: 0.9648, Label: Inlier\n",
      "Indeks-75 → LOF: 1.0563, Label: Inlier\n",
      "Indeks-76 → LOF: 0.9956, Label: Inlier\n",
      "Indeks-77 → LOF: 1.0203, Label: Inlier\n",
      "Indeks-78 → LOF: 0.9136, Label: Inlier\n",
      "Indeks-79 → LOF: 1.2607, Label: Inlier\n",
      "Indeks-80 → LOF: 0.9728, Label: Inlier\n",
      "Indeks-81 → LOF: 0.9884, Label: Inlier\n",
      "Indeks-82 → LOF: 1.0867, Label: Inlier\n",
      "Indeks-83 → LOF: 1.0637, Label: Inlier\n",
      "Indeks-84 → LOF: 1.3545, Label: Inlier\n",
      "Indeks-85 → LOF: 1.2169, Label: Inlier\n",
      "Indeks-86 → LOF: 0.9552, Label: Inlier\n",
      "Indeks-87 → LOF: 1.2067, Label: Inlier\n",
      "Indeks-88 → LOF: 0.9658, Label: Inlier\n",
      "Indeks-89 → LOF: 0.9473, Label: Inlier\n",
      "Indeks-90 → LOF: 1.1655, Label: Inlier\n",
      "Indeks-91 → LOF: 1.0148, Label: Inlier\n",
      "Indeks-92 → LOF: 1.1168, Label: Inlier\n",
      "Indeks-93 → LOF: 1.1470, Label: Inlier\n",
      "Indeks-94 → LOF: 1.1479, Label: Inlier\n",
      "Indeks-95 → LOF: 0.9658, Label: Inlier\n",
      "Indeks-96 → LOF: 1.0679, Label: Inlier\n",
      "Indeks-97 → LOF: 1.0826, Label: Inlier\n",
      "Indeks-98 → LOF: 0.9202, Label: Inlier\n",
      "Indeks-99 → LOF: 0.9150, Label: Inlier\n",
      "Indeks-100 → LOF: 1.2536, Label: Inlier\n",
      "Indeks-101 → LOF: 1.0107, Label: Inlier\n",
      "Indeks-102 → LOF: 1.1062, Label: Inlier\n",
      "Indeks-103 → LOF: 0.9890, Label: Inlier\n",
      "Indeks-104 → LOF: 1.0477, Label: Inlier\n",
      "Indeks-105 → LOF: 1.0490, Label: Inlier\n",
      "Indeks-106 → LOF: 1.8951, Label: Outlier\n",
      "Indeks-107 → LOF: 0.9328, Label: Inlier\n",
      "Indeks-108 → LOF: 1.6245, Label: Outlier\n",
      "Indeks-109 → LOF: 2.0191, Label: Outlier\n",
      "Indeks-110 → LOF: 0.9687, Label: Inlier\n",
      "Indeks-111 → LOF: 0.9910, Label: Inlier\n",
      "Indeks-112 → LOF: 1.0065, Label: Inlier\n",
      "Indeks-113 → LOF: 0.9895, Label: Inlier\n",
      "Indeks-114 → LOF: 1.5494, Label: Outlier\n",
      "Indeks-115 → LOF: 1.1027, Label: Inlier\n",
      "Indeks-116 → LOF: 0.9771, Label: Inlier\n",
      "Indeks-117 → LOF: 1.2398, Label: Inlier\n",
      "Indeks-118 → LOF: 1.1035, Label: Inlier\n",
      "Indeks-119 → LOF: 1.1925, Label: Inlier\n",
      "Indeks-120 → LOF: 1.0517, Label: Inlier\n",
      "Indeks-121 → LOF: 0.9895, Label: Inlier\n",
      "Indeks-122 → LOF: 1.1834, Label: Inlier\n",
      "Indeks-123 → LOF: 1.0600, Label: Inlier\n",
      "Indeks-124 → LOF: 0.9610, Label: Inlier\n",
      "Indeks-125 → LOF: 1.0578, Label: Inlier\n",
      "Indeks-126 → LOF: 0.9770, Label: Inlier\n",
      "Indeks-127 → LOF: 0.9672, Label: Inlier\n",
      "Indeks-128 → LOF: 1.0114, Label: Inlier\n",
      "Indeks-129 → LOF: 1.0610, Label: Inlier\n",
      "Indeks-130 → LOF: 1.0554, Label: Inlier\n",
      "Indeks-131 → LOF: 1.3448, Label: Inlier\n",
      "Indeks-132 → LOF: 1.0114, Label: Inlier\n",
      "Indeks-133 → LOF: 1.0534, Label: Inlier\n",
      "Indeks-134 → LOF: 1.5168, Label: Outlier\n",
      "Indeks-135 → LOF: 1.1915, Label: Inlier\n",
      "Indeks-136 → LOF: 1.0532, Label: Inlier\n",
      "Indeks-137 → LOF: 0.9771, Label: Inlier\n",
      "Indeks-138 → LOF: 1.0047, Label: Inlier\n",
      "Indeks-139 → LOF: 1.0383, Label: Inlier\n",
      "Indeks-140 → LOF: 0.9573, Label: Inlier\n",
      "Indeks-141 → LOF: 1.0383, Label: Inlier\n",
      "Indeks-142 → LOF: 1.0107, Label: Inlier\n",
      "Indeks-143 → LOF: 0.9947, Label: Inlier\n",
      "Indeks-144 → LOF: 0.9620, Label: Inlier\n",
      "Indeks-145 → LOF: 1.0090, Label: Inlier\n",
      "Indeks-146 → LOF: 1.1000, Label: Inlier\n",
      "Indeks-147 → LOF: 1.0355, Label: Inlier\n",
      "Indeks-148 → LOF: 1.0338, Label: Inlier\n",
      "Indeks-149 → LOF: 0.9974, Label: Inlier\n",
      "\n",
      "Jumlah Data Sebelum: 150\n",
      "Jumlah Data Setelah Menghapus Outliers: 137\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hapus kolom non-numerik sebelum menggunakan LOF\n",
    "data = data.drop(columns=['class'])  \n",
    "\n",
    "lof_model = LocalOutlierFactor(n_neighbors=3, metric='euclidean')\n",
    "\n",
    "lof_labels = lof_model.fit_predict(data)  # -1 = outlier, 1 = inlier\n",
    "lof_values = -lof_model.negative_outlier_factor_\n",
    "\n",
    "for i in range(len(data)):\n",
    "    print(f\"Indeks-{i} → LOF: {lof_values[i]:.4f}, Label: {'Outlier' if lof_labels[i] == -1 else 'Inlier'}\")\n",
    "\n",
    "filtered_data = data[lof_labels == 1]  # Hanya simpan data yang bukan outlier\n",
    "\n",
    "print(\"\\nJumlah Data Sebelum:\", len(data))\n",
    "print(\"Jumlah Data Setelah Menghapus Outliers:\", len(filtered_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Hasil Naive Bayes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Model Naïve Bayes setelah menghapus outliers: 0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "filtered_data = filtered_data.copy()  # Hindari efek samping pada DataFrame asli\n",
    "\n",
    "filtered_data['class'] = y[lof_labels == 1].values  # Ambil label dari data asli yang bukan outlier\n",
    "\n",
    "filtered_data = filtered_data.reset_index(drop=True)\n",
    "\n",
    "X = filtered_data.drop(columns=['class'])  # Hanya fitur\n",
    "y = filtered_data['class']  # Label\n",
    "\n",
    "if len(X) < 5:  # Jika data terlalu sedikit setelah filtering, tampilkan peringatan\n",
    "    raise ValueError(\"Data terlalu sedikit setelah menghapus outliers. Coba tingkatkan nilai `n_neighbors` pada LOF.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# === 5. Prediksi & Evaluasi ===\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Akurasi Model Naïve Bayes setelah menghapus outliers:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Hasil Perhitungan Contoh*\n",
    "\n",
    "1. **Dengan Outliers (Akurasi = 1.0)**  \n",
    "   - Model sempurna dalam memprediksi data uji.  \n",
    "   - Kemungkinan besar outlier membuat model terlalu terbiasa (overfitting) dengan data latih.  \n",
    "   - Bisa jadi model hanya \"menghafal\" pola yang ada tanpa benar-benar memahami hubungan antar fitur.  \n",
    "   - Model ini seperti anak yang selalu benar di ujian, tapi ternyata dia menghafal soal ujian, bukan benar-benar memahami materi. Mungkin saja model hanya cocok dengan data ini, tapi kalau dikasih data baru, bisa gagal total.\n",
    "\n",
    "2. **Tanpa Outliers (Akurasi = 0.9643 ≈ 96.4%)**  \n",
    "   - Sedikit penurunan akurasi, tetapi ini lebih realistis untuk data di dunia nyata.  \n",
    "   - Model menjadi lebih generalisasi, artinya lebih baik dalam memprediksi data baru yang belum pernah dilihat sebelumnya.  \n",
    "   - Menghapus outlier membantu mencegah overfitting dan membuat model lebih stabil.  \n",
    "   - Artinya, model sudah belajar dengan baik, bukan sekadar menghafal.\n",
    "   - Model ini sedikit lebih rendah skornya, tapi ini lebih realistis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Kesimpulan***\n",
    "\n",
    "Menurut data yang saya punya, menghapus outlier memang menurunkan sedikit akurasi, tapi ini lebih baik untuk dunia nyata.\n",
    "Karena model tidak hanya cocok untuk data lama, tapi juga bisa bekerja dengan data baru dengan baik. Akan tetapi Jika model digunakan untuk mendeteksi anomali, maka mempertahankan outlier bisa bermanfaat.\n",
    "\n",
    "Ibaratnya:\n",
    "- Dengan outlier → Seperti belajar dengan kunci jawaban, hasilnya sempurna tapi tidak belajar sungguhan.\n",
    "- Tanpa outlier → Seperti belajar konsep dengan baik, jadi kalau ada soal baru, tetap bisa mengerjakan."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
